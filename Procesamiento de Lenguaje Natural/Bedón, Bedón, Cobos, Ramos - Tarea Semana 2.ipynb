{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc4d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arbed\\appdata\\roaming\\python\\python313\\site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (2.9.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\arbed\\appdata\\roaming\\python\\python313\\site-packages (from accelerate>=0.26.0->transformers[torch]) (6.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.2->transformers[torch]) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arbed\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arbed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets \n",
    "%pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ac9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\arbed\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import torch \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments \n",
    "\n",
    "from datasets import Dataset \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae16c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\arbed\\Downloads\\dataset_sentimientos_500.csv\") \n",
    "\n",
    "df.columns = df.columns.str.strip() \n",
    "\n",
    "df = df[['Reseña', 'Sentimiento']].dropna() \n",
    "\n",
    "df['Sentimiento'] = df['Sentimiento'].map({'Positiva': 1, 'Negativa': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfb8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split( \n",
    "\n",
    "    df['Reseña'].tolist(), df['Sentimiento'].tolist(), test_size=0.2, random_state=42 \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc30a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128) \n",
    "\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc2154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({ \n",
    "\n",
    "    'input_ids': train_encodings['input_ids'], \n",
    "\n",
    "    'attention_mask': train_encodings['attention_mask'], \n",
    "\n",
    "    'labels': train_labels \n",
    "\n",
    "}) \n",
    "\n",
    "test_dataset = Dataset.from_dict({ \n",
    "\n",
    "    'input_ids': test_encodings['input_ids'], \n",
    "\n",
    "    'attention_mask': test_encodings['attention_mask'], \n",
    "\n",
    "    'labels': test_labels \n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f39baf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred): \n",
    "\n",
    "    logits, labels = eval_pred \n",
    "\n",
    "    preds = np.argmax(logits, axis=-1) \n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary') \n",
    "\n",
    "    acc = accuracy_score(labels, preds) \n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dacd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e034bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments( \n",
    "\n",
    "    output_dir=\"/results\", \n",
    "\n",
    "    num_train_epochs=3, \n",
    "\n",
    "    per_device_train_batch_size=8, \n",
    "\n",
    "    per_device_eval_batch_size=8, \n",
    "\n",
    "    logging_dir=\"/logs\", \n",
    "\n",
    "    logging_steps=10, \n",
    "\n",
    "    save_steps=50, \n",
    "\n",
    "    save_total_limit=1 \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30687e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arbed\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arbed\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\arbed\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.07774796516944965, metrics={'train_runtime': 112.381, 'train_samples_per_second': 10.678, 'train_steps_per_second': 1.335, 'total_flos': 11716664184000.0, 'train_loss': 0.07774796516944965, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer( \n",
    "\n",
    "    model=model, \n",
    "\n",
    "    args=training_args, \n",
    "\n",
    "    train_dataset=train_dataset, \n",
    "\n",
    "    eval_dataset=test_dataset, \n",
    "\n",
    "    compute_metrics=compute_metrics \n",
    "\n",
    ") \n",
    "\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ff1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arbed\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.0007064539240673184, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_runtime': 4.8473, 'eval_samples_per_second': 20.63, 'eval_steps_per_second': 2.682, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate() \n",
    "\n",
    "print(\"Resultados:\", results) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
